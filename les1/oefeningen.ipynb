{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Les 01\n",
    "\n",
    "## Inleiding\n",
    "\n",
    "Dit is de werkcollege-oefening bij Les 01 van het vak *Advanced Datamining* (BFVH4DMN2). Bestudeer eerst de syllabus behorende bij deze les. Op BlackBoard kun je naast dit iPython/Jupyter notebook een tweetal Python-bestanden vinden. Sla deze op in dezelfde folder als dit notebook. Het verdient aanbeveling om voor elke les een aparte folder aan te maken.\n",
    "\n",
    "- **model.py** bevat een opzet voor een module met object-georiënteerde implementaties van neurale netwerk algoritmen. Het doel van deze oefening is om deze code aan te vullen en uit te werken tot een correct werkend model. Open dit bestand in een code-editor naar keuze. Vergeet niet om tijdens het uitwerken van deze oefening je aanpassingen in de editor telkens op te slaan voordat je de code in dit notebook uitvoert!\n",
    "\n",
    "- **data.py** bevat een aantal functies die helpen bij het genereren en het visualiseren van de gebruikte datasets. Deze functies hoeven maar één keer ingelezen te worden en hoef je niet te wijzigen om deze opdracht correct uit te kunnen voeren. Laten we dus beginnen om deze functies te importeren: plaats de cursor in de cel hieronder en druk op Shift+Enter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'core'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-3dc7e7cd562a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscimath\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mmagic\u001b[0;34m(self, arg_s)\u001b[0m\n\u001b[1;32m   2156\u001b[0m         \u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2157\u001b[0m         \u001b[0mmagic_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmagic_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefilter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mESC_MAGIC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2158\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2160\u001b[0m     \u001b[0;31m#-------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line)\u001b[0m\n\u001b[1;32m   2077\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2078\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2079\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2080\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-104>\u001b[0m in \u001b[0;36mmatplotlib\u001b[0;34m(self, line)\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/IPython/core/magics/pylab.py\u001b[0m in \u001b[0;36mmatplotlib\u001b[0;34m(self, line)\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Available matplotlib backends: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbackends_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0mgui\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_matplotlib\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgui\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_show_matplotlib_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgui\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36menable_matplotlib\u001b[0;34m(self, gui)\u001b[0m\n\u001b[1;32m   2933\u001b[0m         \"\"\"\n\u001b[1;32m   2934\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpylabtools\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2935\u001b[0;31m         \u001b[0mgui\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_gui_and_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgui\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpylab_gui_select\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2936\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2937\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgui\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36mfind_gui_and_backend\u001b[0;34m(gui, gui_select)\u001b[0m\n\u001b[1;32m    257\u001b[0m     \"\"\"\n\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mgui\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mgui\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'auto'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;31m# cbook must import matplotlib only within function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;31m# definitions, so it is safe to import from it here.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcbook\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_string_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmplDeprecation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdedent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m from matplotlib.rcsetup import (defaultParams,\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/matplotlib/cbook.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mweakref\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWeakKeyDictionary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/homes/pkamphuis/.local/lib/python3.5/site-packages/numpy/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_distributor_init\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'core'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import sys, model, data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Laten we eerst eens beter kijken naar de data. De functie `generate()` van de module `data` produceert een verzameling willekeurige instances met continue attributen. Er zijn parameters om het aantal instances te bepalen, het aantal attributen, en om desgewenst de bias en gewichten aan te geven van het model dat gebruikt wordt om de data te genereren. Al deze parameters hebben geschikte default waarden. Een verplichte boolean parameter geeft aan of de dataset nominale uitkomsten dient te hebben t.b.v. classificatie (`nominal=True`) of continue uitkomsten t.b.v. regressie (`nominal=False`). De functie retourneert een lijst met vectoren die de attributen van de instances bevat en een lijst met klasselabels danwel getalwaarden die de bijbehorende uitkomsten bevat. De nominale data zijn lineair separabel; de continue data volgen een lineaire relatie. De algoritmen zouden hierdoor in principe in staat behoren te zijn deze data exact te modelleren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "help(data.generate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Het perceptron\n",
    "\n",
    "Laten we beginnen met een dataset met twee attributen $x_1$ en $x_2$ en met nominale klasselabels $y$ waarop we classificatie kunnen toepassen d.m.v. het perceptron. De functie `data.plot` geeft de instances van beide klassen weer middels een kleurcode (rood voor de klasse $y=-1$ en blauw voor de klasse $y=+1$). Voeg zonodig instructies toe om te verkennen hoe de data in de variabelen `xs` en `ys` is georganiseerd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xs, ys = data.generate(nominal=True)\n",
    "data.plot(xs, ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We beginnen met het implementeren van de instantiatie-methode `__init__()`. Deze heeft een optionele parameter `dim` die aangeeft hoeveel attributen de te classificeren instances zullen hebben. Het perceptron model heeft twee parameters:\n",
    "\n",
    "- een *bias* $b$;\n",
    "\n",
    "- een vector met *gewichten* $\\boldsymbol{w}$.\n",
    "\n",
    "Denk na wat voor typen variabelen je hiervoor wil gebruiken en initialiseer deze met geschikte beginwaarden. Het resultaat is iets als:\n",
    "\n",
    "```\n",
    "def __init__(self, dim=2):\n",
    "    self.bias = ...\n",
    "    self.weights = ...\n",
    "```\n",
    "\n",
    "De weergave-methode `__str__()` is reeds geïmplementeerd; je hoeft deze niet te veranderen, maar voel je vrij om de informatie over een object uit te breiden of anders weer te geven.\n",
    "\n",
    "Als het goed is kun je nu zonder foutmeldingen een nieuw Perceptron-object instantiëren en weergeven. Controleer dat de bias en gewichten juist zijn geinitialiseerd.\n",
    "\n",
    "*Nota bene: de eerste twee regels van de code hieronder dienen om de meest recente versie van je module met het model opnieuw in te lezen nadat je deze opgeslagen hebt vanuit je editor.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del sys.modules['model']   # Unload the old model version\n",
    "from model import *        # Reload the new model version\n",
    "\n",
    "my_perceptron = Perceptron()\n",
    "print(my_perceptron)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De volgende stap is om de code te schrijven die voor een gegeven instance een voorspelling kan doen van het juiste klasselabel op grond van het model van het perceptron:\n",
    "\\begin{equation*}\n",
    "\\hat{y}=\\text{sgn}\\left(b+\\sum_{i}w_{i}\\cdot x_{i}\\right)\n",
    "\\end{equation*}\n",
    "De methode `predict(self, x)` heeft een parameter die de attributen van een instance ontvangt en dient een waarde te retourneren die overeenkomt met het resultaat van de bovenstaande formule.\n",
    "\n",
    "Als je deze code correct hebt geïmplementeerd zou je hieronder de data gevisualiseerd moeten zien op precies dezelfde wijze als hierboven. Omdat het perceptron nog niet getraind is wordt er geen schatting van de scheidingslijn tussen de klassen getoond. Als je geen foutmeldingen krijgt dan functioneert je predictie-methode vooralsnog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del sys.modules['model']   # Unload the old model version\n",
    "from model import *        # Reload the new model version\n",
    "\n",
    "my_perceptron = Perceptron()\n",
    "data.plot(xs, ys, model=my_perceptron)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vervolgens gaan we het perceptron trainen op grond van één instance met gegeven attributen en klasselabel. Gebruik hiervoor de update-regel:\n",
    "\\begin{equation*}\n",
    "\\left\\{ \\begin{array}{c}\n",
    "b\\leftarrow b+\\left(y-\\hat{y}\\right)\\\\\n",
    "w_{i}\\leftarrow w_{i}+\\left(y-\\hat{y}\\right)x_{i}\n",
    "\\end{array}\\right.\n",
    "\\end{equation*}\n",
    "De methode `train(self, x, y)` heeft parameters die de attributen en het klasselabel van een instance ontvangt. Deze functie hoeft niets te retourneren.\n",
    "\n",
    "Als je deze code correct hebt geïmplementeerd zou je hieronder een gekleurde achtergrond moeten zien die weergeeft hoe het perceptron de verschillende waarden van de attributen zou classificeren nadat het één maal getraind is met de eerste instance uit de dataset. Hoogstwaarschijnlijk zal er nog geen correcte grenslijn gevonden worden, maar het perceptron doet wel al voorspellingen en je zou moeten kunnen zien dat de bias en gewichten zijn bijgewerkt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del sys.modules['model']   # Unload the old model version\n",
    "from model import *        # Reload the new model version\n",
    "\n",
    "my_perceptron = Perceptron()\n",
    "my_perceptron.train(xs[0], ys[0])\n",
    "data.plot(xs, ys, model=my_perceptron)\n",
    "print(my_perceptron)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De laatste methode die geïmplementeerd dient te worden heet `fit(self, xs, ys, epochs=0)`. Deze dient de hele dataset te gebruiken om het perceptron te trainen. Er kan een extra argument worden meegegeven dat het aantal te draaien epochs definieert.\n",
    "\n",
    "Met de onderstaande code kun je het perceptron één epoch laten trainen. Het is niet met zekerheid te zeggen of het algoritme dan al tot een correcte oplossing is geconvergeerd. Sterker nog, de oplossing zou er zelfs slechter kunnen uitzien dan die na het trainen met één instance hierboven. Voer de code een aantal keren uit met telkens nieuwe willekeurige data om hier een beter idee van te krijgen. Pas het aantal epochs aan om te zien hoeveel er nodig zijn om een goede oplossing te verkrijgen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del sys.modules['model']   # Unload the old model version\n",
    "from model import *        # Reload the new model version\n",
    "\n",
    "my_perceptron = Perceptron()\n",
    "my_perceptron.fit(xs, ys, epochs=1)\n",
    "data.plot(xs, ys, model=my_perceptron)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rosenblatt heeft bewezen dat het perceptron algoritme gegarandeerd in een eindig aantal stappen convergeert naar een oplossing die alle instances juist classificeert als de data lineair separabel zijn. Dat is hier het geval. Pas je code aan zodat het perceptron automatisch stopt met het draaien van verdere epochs als er in de vorige epoch geen veranderingen in het model meer zijn aangebracht. Bedenk zelf hoe je deze logica het beste kan implementeren.\n",
    "\n",
    "Als de gebruiker om nul epochs verzoekt, of geen waarde meegeeft waardoor de default waarde `epochs=0` geldt, laat dan het algoritme zoveel epochs draaien als maar nodig zijn om te convergeren.\n",
    "\n",
    "Als je dit juist implementeert zou de onderstaande code voor élke dataset een lijn moeten vinden die de beide klassen perfect van elkaar weet te scheiden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del sys.modules['model']   # Unload the old model version\n",
    "from model import *        # Reload the new model version\n",
    "\n",
    "my_perceptron = Perceptron()\n",
    "my_perceptron.fit(xs, ys)\n",
    "data.plot(xs, ys, model=my_perceptron)\n",
    "print(my_perceptron)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gefeliciteerd!** Je hebt zelf een algoritme geïmplementeerd dat een lineair separabele verzameling trainingsdata perfect kan leren onderscheiden.\n",
    "\n",
    "Experimenteer zelf verder hoe het algoritme zich gedraagt. Bijvoorbeeld:\n",
    "\n",
    "- Als je de `data.generate` functie een vooraf bekende bias en gewichten meegeeft om data mee te genereren, convergeert het perceptron dan ook naar deze waarden, of lijken ze erop?\n",
    "\n",
    "- Wat gebeurt er wanneer alle instances van dezelfde klasse zijn (genereer hiertoe bijvoorbeeld een dataset met maar één instance)?\n",
    "\n",
    "- Hoe lang duurt het om te convergeren als het aantal instances toeneemt (bijvoorbeeld $n = 1000$)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lineaire Regressie\n",
    "\n",
    "Vervolgens doen we hetzelfde met instances die een getalwaarde als te voorspellen uitkomst hebben. Eerst maar weer eens een kijkje nemen naar de data. Deze hebben nu continue uitkomsten. De instances zijn daardoor gekleurd langs het hele bereik van de kleurschaal. De ligging van de verschillende kleuren vormt wel een zichtbare geleidelijke overgang."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xs, ys = data.generate(nominal=False)\n",
    "data.plot(xs, ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Begin weer met het schrijven van de instantiatie- en predictie-methoden. Het perceptron van zojuist zou hier een goed uitgangspunt voor moeten vormen. Het model voor lineaire regressie luidt:\n",
    "\\begin{equation*}\n",
    "\\hat{y}=b+\\sum_{i}w_{i}\\cdot x_{i}\n",
    "\\end{equation*}\n",
    "De methode `predict(self, x)` dient in dit geval een getalwaarde te retourneren i.p.v. een klasselabel.\n",
    "\n",
    "Een ongetraind model zou wederom dezelfde grafiek moeten opleveren als hierboven. Controleer dat je geen foutmeldingen krijgt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del sys.modules['model']   # Unload the old model version\n",
    "from model import *        # Reload the new model version\n",
    "\n",
    "my_linear_regression = LinearRegression()\n",
    "data.plot(xs, ys, model=my_linear_regression)\n",
    "print(my_linear_regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vervolgens gaan we het lineaire regressiemodel trainen, eerst weer op grond van één instance met de update-regel:\n",
    "\\begin{equation*}\n",
    "\\left\\{ \\begin{array}{c}\n",
    "b\\leftarrow b+\\alpha\\left(y-\\hat{y}\\right)\\\\\n",
    "w_{i}\\leftarrow w_{i}+\\alpha\\left(y-\\hat{y}\\right)x_{i}\n",
    "\\end{array}\\right.\n",
    "\\end{equation*}\n",
    "De methode `train(self, x, y, alpha=0)` heeft een extra parameter, de learning rate. Deze heeft nu een default waarde $\\alpha=0$, maar dit is niet zo zinvol. Vervang deze door een redelijkere waarde.\n",
    "\n",
    "Na het trainen met één instance wordt het model nog maar weinig aangepast, maar als we een nogal grote learning rate $\\alpha=0.1$ kiezen zou er toch een gradiënt in de achtergrond zichtbaar kunnen worden. De diagonale stippellijn geeft aan waar de voorspelling $\\hat{y}=0$; deze scheidt dus de instances met een voorspelde positieve uitkomst van die met een voorspelde negatieve uitkomst."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del sys.modules['model']   # Unload the old model version\n",
    "from model import *        # Reload the new model version\n",
    "\n",
    "my_linear_regression = LinearRegression()\n",
    "my_linear_regression.train(xs[0], ys[0], alpha=0.1)\n",
    "data.plot(xs, ys, model=my_linear_regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voeg nu tenslotte weer de methode `fit(self, xs, ys, alpha=0, epochs=100)` toe die training toepast op een gegeven aantal hele epochs. Pas de default waarde voor de learning rate weer aan, in overeenkomst met de trainings-functie. In tegenstelling tot bij het perceptron kan het aantal epochs nu niet default op nul worden gesteld; immers, het lineare regressie model convergeert meestal niet naar een exacte uitkomst. Wel wordt er bij een juiste keuze van $\\alpha$ een steeds betere benadering gevonden.\n",
    "\n",
    "Draai de code hieronder. Slaagt je model erin om te convergeren naar een uitkomst die de echte getalwaarden van de instances ogenschijnlijk goed voorspelt?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del sys.modules['model']   # Unload the old model version\n",
    "from model import *        # Reload the new model version\n",
    "\n",
    "my_linear_regression = LinearRegression()\n",
    "my_linear_regression.fit(xs, ys)\n",
    "data.plot(xs, ys, model=my_linear_regression)\n",
    "print(my_linear_regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nogmaals gefeliciteerd!** Je hebt nu ook een algoritme geïmplementeerd dat lineaire regressie kan uitvoeren.\n",
    "\n",
    "Experimenteer weer hoe het algoritme zich gedraagt. Bijvoorbeeld:\n",
    "\n",
    "- Als je nu de `data.generate` functie een vooraf bekende bias en gewichten meegeeft om data mee te genereren, convergeert het lineaire regressie model dan naar deze waarden, of lijken ze erop?\n",
    "\n",
    "- Als je het lineaire regressie model gebruikt om de uitkomsten te voorspellen van een lineair separabele dataset met *nominale* klasselabels, scheidt de stippellijn met $\\hat{y}=0$ de klassen dan even goed als bij perceptron?\n",
    "\n",
    "- Hoe lang duurt het om te convergeren als het aantal instances toeneemt (bijvoorbeeld $n = 1000$)?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
