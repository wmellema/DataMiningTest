{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Les 03\n",
    "\n",
    "## Inleiding\n",
    "\n",
    "Dit is de werkcollege-oefening bij Les 03 van het vak *Advanced Datamining* (BFVH4DMN2). Bestudeer eerst de syllabus behorende bij deze les. Op BlackBoard kun je naast dit iPython/Jupyter notebook een tweetal Python-bestanden vinden. Sla deze op in dezelfde folder als dit notebook. Het verdient aanbeveling om voor elke les een aparte folder aan te maken.\n",
    "\n",
    "- **model.py** bevat een opzet voor een module met object-georiënteerde implementaties van neurale netwerk algoritmen. Het doel van deze oefening is om deze code aan te vullen en uit te werken tot een correct werkend model. Open dit bestand in een code-editor naar keuze. Vergeet niet om tijdens het uitwerken van deze oefening je aanpassingen in de editor telkens op te slaan voordat je de code in dit notebook uitvoert!\n",
    "\n",
    "- **data.py** bevat een aantal functies die helpen bij het genereren en het visualiseren van de gebruikte datasets. Deze functies hoeven maar één keer ingelezen te worden en hoef je niet te wijzigen om deze opdracht correct uit te kunnen voeren.\n",
    "\n",
    "Laten we dus beginnen om deze functies te importeren, samen met wat initialisatie-code: plaats de cursor in de cel hieronder en druk op Shift+Enter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'core'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-1cfa6e444d75>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mimportlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mreload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mmagic\u001b[0;34m(self, arg_s)\u001b[0m\n\u001b[1;32m   2156\u001b[0m         \u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2157\u001b[0m         \u001b[0mmagic_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmagic_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefilter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mESC_MAGIC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2158\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2160\u001b[0m     \u001b[0;31m#-------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line)\u001b[0m\n\u001b[1;32m   2077\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2078\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2079\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2080\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-104>\u001b[0m in \u001b[0;36mmatplotlib\u001b[0;34m(self, line)\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/IPython/core/magics/pylab.py\u001b[0m in \u001b[0;36mmatplotlib\u001b[0;34m(self, line)\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Available matplotlib backends: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbackends_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0mgui\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_matplotlib\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgui\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_show_matplotlib_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgui\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36menable_matplotlib\u001b[0;34m(self, gui)\u001b[0m\n\u001b[1;32m   2933\u001b[0m         \"\"\"\n\u001b[1;32m   2934\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpylabtools\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2935\u001b[0;31m         \u001b[0mgui\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_gui_and_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgui\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpylab_gui_select\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2936\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2937\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgui\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36mfind_gui_and_backend\u001b[0;34m(gui, gui_select)\u001b[0m\n\u001b[1;32m    257\u001b[0m     \"\"\"\n\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mgui\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mgui\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'auto'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;31m# cbook must import matplotlib only within function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;31m# definitions, so it is safe to import from it here.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcbook\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_string_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmplDeprecation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdedent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m from matplotlib.rcsetup import (defaultParams,\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/matplotlib/cbook.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mweakref\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWeakKeyDictionary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/homes/pkamphuis/.local/lib/python3.5/site-packages/numpy/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_distributor_init\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'core'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from importlib import reload\n",
    "\n",
    "import model, data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Het multi-layer perceptron\n",
    "\n",
    "In deze les gaan we de eerder gemaakt neuronen in parallelle en seriële lagen aan elkaar koppelen om krachtigere algoritmen mee te construeren. We gaan meerdere typen lagen definiëren, waaronder lagen met neuronen die lineaire combinaties van attributen maken en daar activatiefuncties op toepassen, en andere neurale lagen die een loss-functie toepassen om de kwaliteit van de fit te berekenen. Deze opzet leent zich voor *inheritance*. In de `model` module is een parent-class `Layer()` voorgedefineerd waarvan we diverse child-classes zullen afleiden, zoals `FullLayer()` voor een fully-connected neurale laag of `LossLayer()` voor de berekening van de loss-functie. Deze parent-class houd een variabele `next` bij die verwijst naar de volgende neurale laag (of `None` als het de laatste laag betreft). De code van de parent-class hoef je deze les in principe niet te veranderen.\n",
    "\n",
    "Begin weer met het implementeren van de instantiatie-methode `__init__()` voor zowel de `FullLayer()` en `LossLayer()` child-classes. De reeds voorgedefinieerde `__str__()` methoden geven een idee welke variabelen deze in elk geval zullen moeten bevatten. Houd er rekening mee dat neurale lagen naast meerdere invoeren ook meer dan één uitvoer kunnen hebben; wel maken alle neuronen in een laag gebruik van dezelfde activatie-functie. Merk op dat de `__init__()` methode van de parent-class door beide child-classes aangeroepen dient te worden in de vorm van `super().__init__()`.\n",
    "\n",
    "De parent-class implementeert reeds een methode `append()` die een extra laag toevoegt aan een bestaand netwerk. Deze wordt geërfd door de child-classes. Hoewel de child-classes op dit moment nog weinig functionele code bevatten kan de werking wel worden geïllustreerd. De onderstaande code zou een neuraal netwerk moeten weergeven dat uit drie lagen bestaat, met correct geinitialiseerde modelparameters en eigenschappen.\n",
    "\n",
    "Overigens werkt ook de weggecommentarieerde concatenatie met het plus-teken doordat de parent-class een `__add__()` methode ondersteunt die op haar beurt weer gebruik maakt van `append()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reload(model)\n",
    "\n",
    "my_network = model.FullLayer(2, 4)        # Een neurale laag met 2 invoeren en 4 uitvoeren\n",
    "my_network.append(model.FullLayer(4, 3))  # Een neurale laag met 4 invoeren en 3 uitvoeren\n",
    "my_network.append(model.LossLayer(3))     # Een loss-laag met 3 invoeren\n",
    "# Of: my_network = model.FullLayer(2, 4) + model.FullLayer(4, 3) + model.LossLayer(3)\n",
    "print(my_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We implementeren eerst weer de `predict()` en `loss()` methoden. Je mag ervan uitgaan dat de laatste laag in het netwerk *altijd* een `LossLayer()` zal zijn. Deze moet immers de kwaliteit van de uiteindelijk gemaakte voorspelling beoordelen met behulp van de loss-functie, want deze uitkomst is hetgeen je wil optimaliseren. De daaraan voorafgaande lagen bestaan voorlopig allemaal uit een `FullLayer()`.\n",
    "\n",
    "Wat betreft predictie gelden de volgende uitgangspunten:\n",
    "\n",
    "- Een fully-connected neurale laag krijgt invoer binnen, berekent hieruit (middels lineaire combinatie en activatiefunctie) diens uitvoer, en geeft die door aan de volgende laag. De volgende laag gaat hier vervolgens de predictie mee vervolgen. De voorspelling die die volgende laag rapporteert wordt tenslotte ook door de fully-connected neurale laag geretourneerd als eigen voorspelling.\n",
    "\n",
    "- Een loss-layer krijgt invoer binnen. Die invoer komt al uit de laatste fully-connected neurale laag, dus dat vormt reeds de voorspelling van het model. De loss-layer kan dus rechtstreeks de invoer retourneren als voorspelling.\n",
    "\n",
    "Kortom, de predictie kan recursief geïmplementeerd worden, waarbij elke fully-connected neurale laag de volgende laag aanroept totdat de recursie beëindigd wordt door de laatste loss-layer. Implementeer op deze manier de `predict()` methoden voor de beide child-classes. Je kan hierbij vermoedelijk putten uit je uitwerkingen van de vorige les, maar houd rekening met het feit dat neurale lagen dit keer meerdere outputs dienen te hebben.\n",
    "\n",
    "De onderstaande code test je predictie voor één neurale laag met één neuron dat twee invoeren heeft en de identiteitsfunctie als activatiefunctie. (Dit is gewoon een lineair regressie model met twee attributen.) Omdat het model nog niet getraind is en alle gewichten default op nul worden gesteld zou de predictie altijd gelijk aan $\\hat{y}=\\left[0\\right]$ moeten zijn (de predictie is nu een vector met lengte één omdat er in dit geval één output is)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reload(model)\n",
    "\n",
    "my_network = model.FullLayer(2, 1, act_func=model.identity_act_func)\n",
    "my_network.append(model.LossLayer(1, loss_func=model.quadratic_loss_func))\n",
    "x = [2.71828, 3.14159]   # Kies twee willekeurige getallen x1 en x2 als invoer\n",
    "print('Prediction =', my_network.predict(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voor de loss geldt ongeveer hetzelfde. De fully-connected neural layer kan wederom zijn uitvoer berekenen uit diens invoer en doorgeven naar de volgende laag, en dan de gerapporteerde loss retourneren. De loss-layer is dit keer verantwoordelijk voor het bepalen voor de loss. Hiertoe dienen door de gebruiker natuurlijk niet alleen de attributen te worden gegeven, maar ook de gewenste uitkomst. Omdat er nu meerdere uitvoeren kunnen zijn is de voorspelling een vector en dient de loss-layer de loss van alle elementen in die vector afzonderlijk te bepalen en op te tellen.\n",
    "\n",
    "Implementeer nu ook de `loss()` methoden voor de beide child-classes. In het onderstaande model dient de uitkomst `0.5` op te leveren omdat de voorspelling $\\hat{y}=0$ en de ware uitkomst $y=1$, met het kwadratische loss $l=\\frac{1}{2}\\left(y-\\hat{y}\\right)^{2}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reload(model)\n",
    "\n",
    "my_network = model.FullLayer(2, 1, act_func=model.identity_act_func)\n",
    "my_network.append(model.LossLayer(1, loss_func=model.quadratic_loss_func))\n",
    "x = [2.71828, 3.14159]   # Kies twee willekeurige getallen x1 en x2 als invoer\n",
    "y = [1.0]   # Geef hier de gewenste uitkomst in de vorm van een lijst met één element\n",
    "print('Loss =', my_network.loss(x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Het XOR-probleem\n",
    "\n",
    "We gaan proberen diverse logische operatoren te modelleren. We zullen hier de conventie hanteren dat de waarde `False` gecodeerd wordt door een getalwaarde $y=-1$ en de waarde `True` door een getalwaarde $y=+1$. Dit stelt ons in staat de signum-functie te gebruiken.\n",
    "\n",
    "De *OR*-operator levert altijd een uitkomst $y=+1$ (`True`), behalve als diens beide inputs gelijk zijn aan $x_1=x_2=-1$ (`False`). Dit gedrag is te modelleren met een single-layer perceptron. Hieronder wordt een dergelijk model gemaakt, maar de bias en gewichten zijn niet juist ingesteld. Bedenk hoe de modelparameters gekozen moeten worden en ga na dat dit model correct werkt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reload(model)\n",
    "\n",
    "xs, ys = [[1.0, 1.0], [-1.0, 1.0], [1.0, -1.0], [-1.0, -1.0]], [[+1.0], [+1.0], [+1.0], [-1.0]]\n",
    "my_network = model.FullLayer(2, 1, act_func=model.signum_act_func)\n",
    "my_network.weights = [[0.0, 0.0]]   # Pas deze waarden aan\n",
    "my_network.biases = [0.0]   # Pas deze waarden aan\n",
    "my_network.append(model.LossLayer(1, loss_func=model.quadratic_loss_func))\n",
    "data.scatter(xs, ys, model=my_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De *AND*-operator levert alleen een uitkomst $y=+1$ (`True`) als diens beide inputs gelijk zijn aan $x_1=x_2=+1$ (`True`). Bepaal ook weer geschikte bias en gewichten voor dit geval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reload(model)\n",
    "\n",
    "xs, ys = [[1.0, 1.0], [-1.0, 1.0], [1.0, -1.0], [-1.0, -1.0]], [[+1.0], [-1.0], [-1.0], [-1.0]]\n",
    "my_network = model.FullLayer(2, 1, act_func=model.signum_act_func)\n",
    "my_network.weights = [[0.0, 0.0]]   # Pas deze waarden aan\n",
    "my_network.biases = [0.0]   # Pas deze waarden aan\n",
    "my_network.append(model.LossLayer(1, loss_func=model.quadratic_loss_func))\n",
    "data.scatter(xs, ys, model=my_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De *XOR*-operator levert $y=+1$ (`True`) als precies één van beide inputs gelijk is aan $+1$ (`True`) en de andere gelijk is aan $-1$ (`False`). Overtuig jezelf dat deze data niet met een single-layer perceptron te modelleren valt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xs, ys = [[1.0, 1.0], [-1.0, 1.0], [1.0, -1.0], [-1.0, -1.0]], [[-1.0], [+1.0], [+1.0], [-1.0]]\n",
    "data.scatter(xs, ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De *XOR*-operatie kan wel worden gemodelleerd met een multi-layer perceptron. Je hebt hiervoor niet meer dan twee lagen nodig, een eerste met breedte twee en een niet-lineaire activatiefunctie (zoals de signum-functie), en een tweede met één output-neuron dat in principe toe kan met de lineaire identiteitsfunctie.\n",
    "\n",
    "Hieronder wordt een dergelijk model opgezet. Pas dit model aan opdat het het *XOR*-probleem kan oplossen. Kies hiertoe geschikte biases en gewichten, pas zonodig de activatiefuncties aan, of voeg desgewenst meer neuronen of neurale lagen toe.\n",
    "\n",
    "Kun je meerdere uiteenlopende modellen vinden die allemaal toch tot een juiste classificatie leiden?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reload(model)\n",
    "\n",
    "hidden = model.FullLayer(2, 2, act_func=model.signum_act_func)\n",
    "hidden.weights = [[0.0, 0.0], [0.0, 0.0]]   # Pas deze waarden aan\n",
    "hidden.biases = [0.0, 0.0]   # Pas deze waarden aan\n",
    "output = model.FullLayer(2, 1, act_func=model.identity_act_func)\n",
    "output.weights = [[0.0, 0.0]]   # Pas deze waarden aan\n",
    "output.biases = [0.0]   # Pas deze waarden aan\n",
    "loss = model.LossLayer(1, loss_func=model.quadratic_loss_func)\n",
    "my_network = hidden + output + loss\n",
    "data.scatter(xs, ys, model=my_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Wordt vervolgd...*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
